{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\deep0\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\deep0\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\deep0\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\deep0\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\deep0\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas matplotlib seaborn scikit-learn tensorflow keras keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder, StandardScaler\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (confusion_matrix, classification_report, roc_auc_score, roc_curve, \n\u001b[0;32m     12\u001b[0m                              precision_recall_fscore_support, accuracy_score)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, regularizers\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 2. Imports\n",
    "# -----------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, roc_auc_score, roc_curve, \n",
    "                             precision_recall_fscore_support, accuracy_score)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import keras_tuner as kt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 3. Data Loading & EDA\n",
    "# -----------------------------------------------------------\n",
    "df = pd.read_csv('balanced_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values and class distribution\n",
    "print(df.isnull().sum())\n",
    "print(df['City'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- Encode target labels\n",
    "- Scale features\n",
    "- Reshape for LSTM (samples, timesteps, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "df['City_enc'] = le.fit_transform(df['City'])\n",
    "num_classes = df['City_enc'].nunique()\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(['City', 'City_enc'], axis=1).values\n",
    "y = df['City_enc'].values\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# LSTM expects 3D input: (samples, timesteps, features)\n",
    "# We'll use timesteps=1 (can be tuned for sequence data)\n",
    "X_lstm = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "# One-hot encode target for Keras\n",
    "y_cat = to_categorical(y, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 4. Model Building Function\n",
    "# -----------------------------------------------------------\n",
    "def build_lstm_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    # LSTM layer\n",
    "    model.add(layers.LSTM(\n",
    "        units=hp.Int('units', min_value=32, max_value=128, step=32),\n",
    "        input_shape=(X_lstm.shape[1], X_lstm.shape[2]),\n",
    "        return_sequences=False,\n",
    "        kernel_regularizer=regularizers.l2(hp.Choice('l2', [0.0, 1e-4, 1e-3]))\n",
    "    ))\n",
    "    # Dropout\n",
    "    model.add(layers.Dropout(hp.Float('dropout', 0.2, 0.5, step=0.1)))\n",
    "    # Dense output\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=hp.Choice('lr', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with Keras Tuner\n",
    "\n",
    "We use Keras Tuner to find the best LSTM units, dropout, L2 regularization, and learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 5. Hyperparameter Tuning (on a single fold for speed)\n",
    "# -----------------------------------------------------------\n",
    "tuner = kt.RandomSearch(\n",
    "    build_lstm_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='kt_dir',\n",
    "    project_name='lstm_aqi'\n",
    ")\n",
    "\n",
    "# Use a small validation split for tuning\n",
    "tuner.search(X_lstm, y_cat, epochs=20, validation_split=0.2, verbose=1,\n",
    "             callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)])\n",
    "\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "print(\"Best hyperparameters:\", best_hp.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-Fold Cross-Validation\n",
    "\n",
    "We use the best hyperparameters found above for all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 6. K-Fold Cross-Validation\n",
    "# -----------------------------------------------------------\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "histories = []\n",
    "fold_metrics = []\n",
    "best_val_acc = 0\n",
    "best_model = None\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_lstm, y)):\n",
    "    print(f\"\\n--- Fold {fold+1} ---\")\n",
    "    X_train, X_val = X_lstm[train_idx], X_lstm[val_idx]\n",
    "    y_train, y_val = y_cat[train_idx], y_cat[val_idx]\n",
    "    y_val_labels = y[val_idx]\n",
    "    \n",
    "    # Build model with best hyperparameters\n",
    "    model = build_lstm_model(best_hp)\n",
    "    \n",
    "    # Early stopping\n",
    "    es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=best_hp.get('batch_size', 32),\n",
    "        callbacks=[es],\n",
    "        verbose=1\n",
    "    )\n",
    "    histories.append(history)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_prob = model.predict(X_val)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_val_labels, y_pred)\n",
    "    pr, rc, f1, _ = precision_recall_fscore_support(y_val_labels, y_pred, average=None, zero_division=0)\n",
    "    cm = confusion_matrix(y_val_labels, y_pred)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr')\n",
    "    except:\n",
    "        auc = None\n",
    "    \n",
    "    fold_metrics.append({\n",
    "        'accuracy': acc,\n",
    "        'precision': pr,\n",
    "        'recall': rc,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'cm': cm,\n",
    "        'y_val': y_val_labels,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_prob': y_pred_prob\n",
    "    })\n",
    "    \n",
    "    # Save best model\n",
    "    val_acc = max(history.history['val_accuracy'])\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model = model\n",
    "        model.save('best_lstm_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization\n",
    "\n",
    "We plot training/validation loss and accuracy, confusion matrix, and ROC curve for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 7. Visualization & Aggregation\n",
    "# -----------------------------------------------------------\n",
    "for i, (history, metrics) in enumerate(zip(histories, fold_metrics)):\n",
    "    # Loss & Accuracy\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title(f'Fold {i+1} - Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "    plt.title(f'Fold {i+1} - Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(metrics['cm'], annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(f'Fold {i+1} - Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC Curve (macro-average)\n",
    "    if metrics['auc'] is not None:\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        for j in range(num_classes):\n",
    "            fpr[j], tpr[j], _ = roc_curve(metrics['y_val']==j, metrics['y_pred_prob'][:,j])\n",
    "            plt.plot(fpr[j], tpr[j], label=f'Class {le.classes_[j]}')\n",
    "        plt.plot([0,1],[0,1],'k--')\n",
    "        plt.title(f'Fold {i+1} - ROC Curve')\n",
    "        plt.xlabel('FPR')\n",
    "        plt.ylabel('TPR')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate metrics\n",
    "accs = [m['accuracy'] for m in fold_metrics]\n",
    "f1s = [np.mean(m['f1']) for m in fold_metrics]\n",
    "aucs = [m['auc'] for m in fold_metrics if m['auc'] is not None]\n",
    "\n",
    "print(f\"Average Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "print(f\"Average F1-score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
    "if aucs:\n",
    "    print(f\"Average AUC: {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
